{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "cifar100-gan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "us5S0MeWAtW9"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import keras \n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout \n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D \n",
        "from keras.layers.advanced_activations import LeakyReLU \n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D \n",
        "from keras.models import Sequential, Model \n",
        "from keras.optimizers import Adam,SGD \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3--sulwhAtW_"
      },
      "source": [
        "from keras.layers.convolutional import UpSampling2D, Conv2D \n",
        "from keras.models import Sequential, Model \n",
        "from keras.optimizers import Adam,SGD "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R32mzxBaAtXA"
      },
      "source": [
        "#Loading the CIFAR10 data \n",
        "(x_train, y_train), (_, _) = keras.datasets.cifar100.load_data() \n",
        "\n",
        "save_path = '/kaggle/working/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GxqgOUuXAtXB"
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jZCi5QZEAtXC"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eDL-k6e9AtXC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "n = 10\n",
        "plt.figure(figsize=(25,10))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_train[i])\n",
        "    ax.get_xaxis().set_visible(True)\n",
        "    ax.get_yaxis().set_visible(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Y4APx6c6AtXC"
      },
      "source": [
        "#Defining the Input shape \n",
        "image_shape = (32, 32, 3) \n",
        "\n",
        "dimension = 100\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RjV_QsEZAtXC"
      },
      "source": [
        "def build_generator(): \n",
        "\n",
        "\t\tmodel = Sequential() \n",
        "\n",
        "\t\t#Building the input layer \n",
        "\t\tmodel.add(Dense(128 * 8 * 8, activation=\"relu\", \n",
        "\t\t\t\t\t\tinput_dim=dimension)) \n",
        "\t\tmodel.add(Reshape((8, 8, 128))) \n",
        "\t\t\n",
        "\t\tmodel.add(UpSampling2D()) \n",
        "\t\t\n",
        "\t\tmodel.add(Conv2D(128, kernel_size=3, padding=\"same\")) \n",
        "\t\tmodel.add(BatchNormalization(momentum=0.8)) \n",
        "\t\tmodel.add(Activation(\"relu\")) \n",
        "\t\t\n",
        "\t\tmodel.add(UpSampling2D()) \n",
        "\t\t\n",
        "\t\tmodel.add(Conv2D(64, kernel_size=3, padding=\"same\")) \n",
        "\t\tmodel.add(BatchNormalization(momentum=0.8)) \n",
        "\t\tmodel.add(Activation(\"relu\")) \n",
        "\t\t\n",
        "\t\tmodel.add(Conv2D(3, kernel_size=3, padding=\"same\")) \n",
        "\t\tmodel.add(Activation(\"tanh\")) \n",
        "\n",
        "\t\tnoise = Input(shape=(dimension,)) \n",
        "\t\timage = model(noise) \n",
        "\n",
        "\t\treturn Model(noise, image) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6v3Vu8pIAtXD"
      },
      "source": [
        "def build_discriminator(): \n",
        "\n",
        "\t\tmodel = Sequential() \n",
        "\n",
        "\t\tmodel.add(Conv2D(32, kernel_size=3, strides=2, \n",
        "\t\t\t\t\t\tinput_shape=image_shape, padding=\"same\")) \n",
        "\t\tmodel.add(LeakyReLU(alpha=0.2)) \n",
        "\t\tmodel.add(Dropout(0.2)) \n",
        "\t\t\n",
        "\t\tmodel.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\")) \n",
        "\t\tmodel.add(ZeroPadding2D(padding=((0,1),(0,1)))) \n",
        "\t\tmodel.add(BatchNormalization(momentum=0.8)) \n",
        "\t\tmodel.add(LeakyReLU(alpha=0.2)) \n",
        "\t\tmodel.add(Dropout(0.2)) \n",
        "\t\t\n",
        "\t\tmodel.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\")) \n",
        "\t\tmodel.add(BatchNormalization(momentum=0.8)) \n",
        "\t\tmodel.add(LeakyReLU(alpha=0.2)) \n",
        "\t\tmodel.add(Dropout(0.2)) \n",
        "\t\t\n",
        "\t\tmodel.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\")) \n",
        "\t\tmodel.add(BatchNormalization(momentum=0.8)) \n",
        "\t\tmodel.add(LeakyReLU(alpha=0.2)) \n",
        "\t\tmodel.add(Dropout(0.2)) \n",
        "\t\t\n",
        "\t\t#Building the output layer \n",
        "\t\tmodel.add(Flatten()) \n",
        "\t\tmodel.add(Dense(1, activation='sigmoid')) \n",
        "\n",
        "\t\timage = Input(shape=image_shape) \n",
        "\t\tvalidity = model(image) \n",
        "\n",
        "\t\treturn Model(image, validity) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZbfvLaMVAtXD"
      },
      "source": [
        "def display_images(): \n",
        "        r, c = 5,5\n",
        "        noise = np.random.normal(0, 1, (r * c,dimension)) \n",
        "        generated_images = generator.predict(noise) \n",
        "\n",
        "        #Scaling the generated images \n",
        "        generated_images = 0.5 * generated_images + 0.5\n",
        "                    \n",
        "        fig, axs = plt.subplots(r, c) \n",
        "        count = 0\n",
        "        for i in range(r): \n",
        "            for j in range(c): \n",
        "                axs[i,j].imshow(generated_images[count, :,:,]) \n",
        "                axs[i,j].axis('off') \n",
        "                plt.savefig(f'{save_path}/gan-images_epoch-{epoch}.png')\n",
        "                count += 1\n",
        "        plt.show() \n",
        "        plt.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_hj6CL5BAtXE"
      },
      "source": [
        "# Building and compiling the discriminator \n",
        "discriminator = build_discriminator() \n",
        "discriminator.compile(loss='binary_crossentropy', \n",
        "\t\t\t\t\toptimizer=Adam(0.0002,0.5), \n",
        "\t\t\t\t\tmetrics=['accuracy']) \n",
        "\n",
        "#Making the Discriminator untrainable \n",
        "#so that the generator can learn from fixed gradient \n",
        "discriminator.trainable = False\n",
        "\n",
        "# Building the generator \n",
        "generator = build_generator() \n",
        "\n",
        "#Defining the input for the generator and generating the images \n",
        "dummy = Input(shape=(dimension,)) \n",
        "image = generator(dummy) \n",
        "\n",
        "\n",
        "#Checking the validity of the generated image \n",
        "valid = discriminator(image) \n",
        "\n",
        "#Defining the combined model of the Generator and the Discriminator \n",
        "combined_network = Model(dummy, valid) \n",
        "combined_network.compile(loss='binary_crossentropy', \n",
        "\t\t\t\t\t\toptimizer=Adam(0.0002,0.5)) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iqpI_CYVAtXE"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "generator.summary()\n",
        "#plt.savefig('/kaggle/working/generator.png')\n",
        "plot_model(generator, to_file='/kaggle/working/generator.png', show_shapes=True,show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6QFQ_S43AtXF"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "discriminator.summary()\n",
        "plot_model(discriminator, to_file='/kaggle/working/discriminator.png', show_shapes=True,show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cO-vbeUPAtXG"
      },
      "source": [
        "num_epochs=50000\n",
        "batch_size=32\n",
        "display_after=1000\n",
        "losses=[] \n",
        "\n",
        "#Normalizing the input \n",
        "x_train = (x_train - 127.5) / 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0l5wdTyFAtXG"
      },
      "source": [
        "#Defining the Adversarial ground truths \n",
        "valid = np.ones((batch_size, 1)) \n",
        "\n",
        "#Adding some noise \n",
        "valid += 0.05 * np.random.random(valid.shape) \n",
        "fake = np.zeros((batch_size, 1)) \n",
        "fake += 0.05 * np.random.random(fake.shape) \n",
        "\n",
        "for epoch in range(num_epochs): \n",
        "            \n",
        "            #Training the Discriminator \n",
        "              \n",
        "            #Sampling a random half of images \n",
        "            index = np.random.randint(0, x_train.shape[0], batch_size) \n",
        "            images = x_train[index] \n",
        "\n",
        "            #Sampling noise and generating a batch of new images \n",
        "            noise = np.random.normal(0, 1, (batch_size, dimension)) \n",
        "            generated_images = generator.predict(noise) \n",
        "\n",
        "\n",
        "            #Training the discriminator to detect more accurately \n",
        "            #whether a generated image is real or fake \n",
        "            discm_loss_real = discriminator.train_on_batch(images, valid) \n",
        "            discm_loss_fake = discriminator.train_on_batch(generated_images, fake) \n",
        "            discm_loss = 0.5 * np.add(discm_loss_real, discm_loss_fake) \n",
        "          \n",
        "            #Training the Generator \n",
        "            \n",
        "            #Training the generator to generate images \n",
        "            #which pass the authenticity test \n",
        "            genr_loss = combined_network.train_on_batch(noise, valid) \n",
        "             \n",
        "            #Tracking the progress\t\t\t\t \n",
        "            if epoch % display_after == 0: \n",
        "              display_images()\n",
        "            ''''plt.savefig(f'{save_path}/gan-images_epoch-{epoch}.png')\n",
        "            plt.show()'''\n",
        "            \n",
        "       \n",
        "                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LeljVLdlAtXH"
      },
      "source": [
        "#Plotting some of the original images \n",
        "solid = x_train[:30] \n",
        "solid = 0.5 * solid + 0.5\n",
        "f, ax = plt.subplots(5,6, figsize=(15,8)) \n",
        "for i, image in enumerate(solid): \n",
        "\tax[i//6, i%6].imshow(image) \n",
        "\tax[i//6, i%6].axis('on') \n",
        "plt.savefig(\"/kaggle/working/originalimages.png\")\n",
        "plt.show() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JCeZEME3AtXI"
      },
      "source": [
        "#Plotting some of the last batch of generated images \n",
        "noise = np.random.normal(size=(30, dimension)) \n",
        "generated_images = generator.predict(noise) \n",
        "generated_images = 0.5 * generated_images + 0.5\n",
        "f, ax = plt.subplots(5,6, figsize=(15,8)) \n",
        "for i, image in enumerate(generated_images): \n",
        "\tax[i//6, i%6].imshow(image) \n",
        "\tax[i//6, i%6].axis('on') \n",
        "plt.savefig(\"/kaggle/working/reconstructedImages.png\")\n",
        "plt.show() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MLCcwvOTAtXI"
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QosGjaAdAtXI"
      },
      "source": [
        "import re\n",
        "import sys\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def func(x):\n",
        "  for i in x:\n",
        "    if(i.isdigit()):\n",
        "      print(i)\n",
        "      return int(i)\n",
        "  return 10000000000\n",
        "\n",
        "image_names = os.listdir(save_path)\n",
        "\n",
        "frames = []\n",
        "#for image in sorted(image_names, key=lambda name: int(''.join(i for i in name if i.isdigit()))):\n",
        "for image in sorted(image_names, key=func):\n",
        "    if(bool(re.search(r'\\d', image))):\n",
        "        print(image)\n",
        "        frames.append(Image.open(save_path + '/' + image))\n",
        "\n",
        "frames[0].save('/kaggle/working/reconstruction_process.gif', format='GIF', append_images=frames[1:], save_all=True, duration=100, loop=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3XCyPF6WAtXJ"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(\"../working/reconstruction_process.gif\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rELgVn2QAtXK"
      },
      "source": [
        "save all the gifs, images and models to the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "T8TbggKgAtXL"
      },
      "source": [
        "discriminator.save('/kaggle/working/discriminator.h5')\n",
        "generator.save('/kaggle/working/dcgenerator.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}